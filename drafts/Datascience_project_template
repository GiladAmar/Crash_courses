


DS_structure:
    model_classes:
        Class:
            Model definition:
                
                def train()
                def generator_train()
                def predict()
                def test()
                def plot_sample()
                def plot_kpis()
                def load_model()
                def resume_training()
                def bootstrap_labelling()
                def tune_hyper_params
                def create_ensemble

            Losses:
                def custom_loss_func

            Data_processing:
                Aligner Class
                def explore_data
                def read_from_dir
                def save_to_dir
                def prepare_images
                def get_generator
                def get_batch

            Params:
    models:
        *.hdf5
        ...
    prepared_data:
        *.npy

    src_data:
        soft link to data source

    plots:
        *.jpg

    production_pipeline:
        *.py

    Scripts:
        prepare_data
        train
        test
        production
        test_production

    requirements.txt
    requirements_human.txt




* plotting results as it runs, like debug mode
* saving training sessions in timstamps folders with associated parameters
* saving training results (losses, time taken etc) too
* save scipy pkl items but not as pkls

* explore created embeddings
* create embeddings with different models and explore hyper-param space
* bootstrapper does/does not over write files already in the directory but classified differently
* prevent script from using too much memory/gpu/cpu
* video / image series for debugging